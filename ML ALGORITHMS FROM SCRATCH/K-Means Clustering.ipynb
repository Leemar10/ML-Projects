{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de20a863-ecac-498b-9b11-713a8e889bc9",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is the **fifth notebook** in my machine learning series.  \n",
    "In the [previous notebook](https://www.kaggle.com/code/rameelsohail/k-nearest-neighbors), we implemented the **K-Nearest Neighbors (KNN)** algorithm.\n",
    "\n",
    "In this notebook, we'll be implementing our first **clustering** algorithm ‚Äî **K-Means**.  \n",
    "We‚Äôll be using the classic **Iris dataset** to explore how K-Means groups similar data points together without labeled outputs.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47982d-ac23-4a3e-b415-b65915ec4078",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e1c7df-69fc-4e8e-8b29-6c4503702603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d841a72-e32b-46dd-b56e-1976d8ced296",
   "metadata": {},
   "source": [
    "# Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffcd11b-ad19-4dbb-a300-d93835976b8c",
   "metadata": {},
   "source": [
    "## Dataset ‚Äî Iris \n",
    "\n",
    "In this notebook, we'll be using the **Iris dataset**, one of the most famous datasets in machine learning.  \n",
    "\n",
    "The **Iris dataset** was first introduced in **R.A. Fisher‚Äôs 1936 paper**, *‚ÄúThe Use of Multiple Measurements in Taxonomic Problems‚Äù*, and is also available on the **UCI Machine Learning Repository**.  \n",
    "\n",
    "It contains **three species of Iris flowers**, with **50 samples each**, and includes measurements of their physical attributes.  \n",
    "One of the species is **linearly separable**, while the other two are **not linearly separable**, making this dataset a great starting point for classification tasks.  \n",
    "\n",
    "### Columns:\n",
    "- **Id** ‚Äî Unique identifier for each observation  \n",
    "- **SepalLengthCm** ‚Äî Length of the sepal (in cm)  \n",
    "- **SepalWidthCm** ‚Äî Width of the sepal (in cm)  \n",
    "- **PetalLengthCm** ‚Äî Length of the petal (in cm)  \n",
    "- **PetalWidthCm** ‚Äî Width of the petal (in cm)  \n",
    "- **Species** ‚Äî Type of Iris flower (Setosa, Versicolor, Virginica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2769e67-d9ca-4f64-b681-13f1201eb577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Iris.csv')\n",
    "df.drop('Id', axis=1, inplace=True) # Drop redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7799e1f3-8434-4daa-9939-5643dadde5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the features\n",
    "X = df.iloc[:,:-1]\n",
    "\n",
    "# Setting the labels\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab8e605-b676-4f17-8bda-ed98da191e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e48276-02f2-4929-a678-2fc95a53ea8b",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05d8e0d-f899-4917-bd55-d56a1b2f69ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.pie(df, 'Species', template='plotly_dark', title='Data Distribution',color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d27ab2-077b-484c-ae42-5e8d670c7946",
   "metadata": {},
   "source": [
    "This plot shows that there is an **equal number of samples for each class**, making the dataset **balanced**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80198288-8648-49e2-a127-7015f360505f",
   "metadata": {},
   "source": [
    "### Sepal Length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3ff3a2-c7e3-449c-a953-e7bb33a4c124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_6.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(df, x='Species', y='SepalLengthCm', color='Species', template='plotly_dark',color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ef6105-fca1-4f66-9a08-f43178ee223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(df, x='SepalLengthCm', color='Species', template='plotly_dark', color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'], nbins=50)\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f09b0-188b-4665-8d65-779ad0e21d75",
   "metadata": {},
   "source": [
    "These plots show that:  \n",
    "- **Setosa** flowers are much smaller, making them **linearly separable** from the other two classes.  \n",
    "- **Virginica** flowers are generally the largest and contain a outlier.  \n",
    "- It is difficult to distinguish between **Versicolor** and **Virginica**, as their features overlap.\n",
    "- The amount of overlap between **Versicolor** and **Virginica** make this a less useful feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90dacb-3a90-48b6-b31e-1e927117805f",
   "metadata": {},
   "source": [
    "### Petal Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1156bb8-1c6d-456b-8929-bd1e852bb576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_8.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(df, x='Species', y='PetalLengthCm', color='Species', template='plotly_dark', color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695a1f12-6f1f-4b74-a86a-0e64ababdb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_9.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(df, x='PetalLengthCm', color='Species', template='plotly_dark', nbins=30, color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3360db4-a78a-409d-8b74-d009b5261625",
   "metadata": {},
   "source": [
    "These plots show that:\n",
    "- Again **Setosa** has a much smaller **Petal Length** comapared to the other two classes.\n",
    "- **Virginica** has the largest **Petal Length.\n",
    "- There is some overlap between **Versicolor** and **Virginica**, regardless of that **Petal Length** shows some differentiation between the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919061c-6fa9-4862-b181-99bea95a0876",
   "metadata": {},
   "source": [
    "### Sepal Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f0a0676-4033-480d-b72a-642fdf2af2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_10.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(df, x='Species', y='SepalWidthCm', color='Species', template='plotly_dark', color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e37f42-129b-4914-ae61-8a8cce26945f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_11.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(df, x='SepalWidthCm', color='Species', template='plotly_dark', nbins=30, color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096eeb4d-7973-4831-8d17-22ba40b6346b",
   "metadata": {},
   "source": [
    "These plots show that:\n",
    "- **Setosa** has the largest **Sepal width**.\n",
    "- **Versicolor** has the smallest **Sepal width**.\n",
    "- There is alot of overlap between the classes, showing that **Sepal Width** might not be a useful feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fa790-16a4-475b-ab9a-602cf4c9fb7c",
   "metadata": {},
   "source": [
    "### Petal Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eadf94a-5bcf-4bc8-bf5b-61dbc2c6c359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(df, x='Species', y='PetalWidthCm', color='Species', template='plotly_dark', color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd97aa4e-7e88-41d4-8dae-38c84fd0670d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_13.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(df, x='PetalWidthCm', color='Species', template='plotly_dark', nbins=20, color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc416eac-6736-4baa-8b3f-36cd98e077a4",
   "metadata": {},
   "source": [
    "These plots show that:\n",
    "- **Setosa** has much smaller **PetalWidth** than the other 2 classes, it also has 2 outliers.\n",
    "- Again the difference is less clear between **Virginica** and **Versicolor**\n",
    "- Overall this seems like an PetalWidth might be useful in making good predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7381838-edb8-4d9c-8b94-8469e3813ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_14.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(df, x='SepalLengthCm', y='SepalWidthCm', size='PetalLengthCm', color='Species', template='plotly_dark', color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8859d148-09c3-4188-a642-31f211ec5290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_15.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(df, x='SepalLengthCm', y='SepalWidthCm', size='PetalWidthCm', color='Species', template='plotly_dark', color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d922016-8a5b-4433-8699-a4d3dd1f9029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_16.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(df, x='PetalLengthCm', y='PetalWidthCm', size='SepalLengthCm', color='Species', template='plotly_dark', color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fe05c25-9b29-44e0-9aee-0a335855d896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_17.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(df, x='PetalLengthCm', y='PetalWidthCm', size='SepalWidthCm', color='Species', template='plotly_dark', color_discrete_sequence=['#491D8B','#7D3AC1','#EB548C'])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f2914-d7df-45af-a17f-1c28a4d644a0",
   "metadata": {},
   "source": [
    "These plots show us that:\n",
    "- **Setosa** is the smaller of the three flower species.\n",
    "- **Virginica** is the largest of the three flower species.\n",
    "- **Versicolor** and **Virginica** show overlap , making them difficult to distinguish.\n",
    "- There is a positive correlation between some of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abd16b-bc5d-4471-8da7-0a9163dfc6f0",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6534b2-dcef-4edc-a190-958399f055f6",
   "metadata": {},
   "source": [
    "## What is K-Means?\n",
    "\n",
    "**K-Means Clustering** is an **unsupervised machine learning** algorithm that groups data points into clusters based on their similarity.  \n",
    "Unlike **supervised learning**, where models are trained on labeled data, **K-Means** is used when the dataset is **unlabeled** (though the Iris dataset does contain labels, we‚Äôll ignore them for learning purposes).  \n",
    "The goal is to uncover hidden patterns or natural groupings within the data.\n",
    "\n",
    "**Example:**  \n",
    "An online store can use K-Means to segment customers into groups such as **‚ÄúBudget Shoppers,‚Äù ‚ÄúFrequent Buyers,‚Äù** and **‚ÄúBig Spenders‚Äù** based on their purchasing behavior.\n",
    "\n",
    "---\n",
    "\n",
    "## How does K-Means work?\n",
    "\n",
    "Suppose we have a dataset consisting of items, each represented by a vector of feature values.  \n",
    "Our goal is to categorize these items into groups based on similarity. The parameter **k** represents the number of clusters we want to form.\n",
    "\n",
    "K-Means groups the data into **k clusters** by minimizing the **distance** between each data point and its assigned cluster centroid.  \n",
    "The **Euclidean distance** is commonly used as the similarity measure.\n",
    "\n",
    "The algorithm follows these main steps:\n",
    "\n",
    "1. **Initialization:** Randomly select *k* initial cluster centroids.  \n",
    "2. **Assignment Step:** Assign each data point to the nearest centroid, forming clusters.  \n",
    "3. **Update Step:** Recalculate each centroid as the mean of all points assigned to that cluster.  \n",
    "4. **Repeat:** Continue steps 2‚Äì3 until the centroids stop changing or a maximum number of iterations is reached.\n",
    "\n",
    "---\n",
    "\n",
    "### Initialization\n",
    "We start by randomly selecting *k* points from the dataset as the **initial centroids**.  \n",
    "These act as the centers of the clusters in the first iteration.\n",
    "\n",
    "---\n",
    "\n",
    "### Assignment Step\n",
    "For each data point in our training set, we determine which centroid it is closest to. This is done b0y measuring the distance between the data point and each centroid and selecting the centroid with the smallest distance as the closest one. We use an index notation, denoted as  $c^{(i)}$, to represent the index of the closest centroid to the data point $x^{(i)}$\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Computing Cluster Means\n",
    "Once all data points are assigned to their nearest centroids, we recompute the **centroid of each cluster** as the mean of all points belonging to that cluster.  \n",
    "Mathematically, for each cluster \\( j \\):\n",
    "\n",
    "$$\n",
    "\\mu_j = \\frac{1}{|C_j|} \\sum_{i \\in C_j} x^{(i)}\n",
    "$$\n",
    "\n",
    "The **objective (cost) function** that K-Means minimizes is the **total within-cluster variance** (or **sum of squared distances**) between data points and their assigned centroids:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{m} \\| x^{(i)} - \\mu_j \\|^2\n",
    "$$\n",
    "\n",
    "**where**:\n",
    "- $k$: number of clusters  \n",
    "- $m$: number of data points  \n",
    "- $x^{(i)}$: the *i-th* data point  \n",
    "- $\\mu_j$: the centroid of cluster *j*  \n",
    "\n",
    "---\n",
    "\n",
    "The algorithm repeats the assignment and recomputation of centroids until convergence, where the centroids no longer change significantly or a specified number of iterations is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d79cb19c-d120-4f01-9acc-1d98734fe833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans:\n",
    "    \"\"\"\n",
    "    K means clustering implementation\n",
    "    Parameters:\n",
    "    K(int) : Number of independent clusters(centroids)\n",
    "\n",
    "    Attributes:\n",
    "    __init__(self, K, max_iters=10) : Initializes the number of centroids and maximum iterations.\n",
    "    initialze_centroids(self, X) : Initializes the centroids to K random points in the data.\n",
    "    assign_centroids(self, X) : Assigns each data point to the nearest centroid.\n",
    "    compute_mean(self, X, points) : Computes the mean distance of all the points belonging to a specific centroid.\n",
    "    fit(self, X) : Driver of our Kmeans class.\n",
    "    \"\"\"\n",
    "    def __init__(self, K, max_iters=10):\n",
    "        assert K > 0, \"K must be greater than 0.\"\n",
    "        assert max_iters > 0, \"The number of max iterations must be greater than 0.\"\n",
    "        self.K = K\n",
    "        self.max_iters = max_iters\n",
    "        self.centroids = None\n",
    "\n",
    "    def initialize_centroids(self, X):\n",
    "        assert X.shape[0] >= self.K, \"There must be atleast K samples in our dataset.\"\n",
    "        \n",
    "        random_idx = np.random.permutation(X.shape[0])\n",
    "        centroids_idx = random_idx[:self.K]\n",
    "        self.centroids = X[centroids_idx]\n",
    "\n",
    "    def assign_centroids(self, X):\n",
    "        \"\"\"\n",
    "            Assign each point in our dataset to the closest centroid.\n",
    "\n",
    "            Parameters:\n",
    "                X (np.ndarray) : Samples\n",
    "\n",
    "            Returns:\n",
    "                points (np.ndarray) : Array consisting of indexes of the closest centroid to each sample in the dataset\n",
    "        \"\"\"\n",
    "        points = []\n",
    "        X = np.expand_dims(X, axis=1)\n",
    "        distances = np.linalg.norm(X-self.centroids, axis=-1)\n",
    "        points = np.argmin(distances, axis=1)\n",
    "\n",
    "        assert points.shape[0] == X.shape[0], \"The number points must be equal to the samples.\"\n",
    "        return points\n",
    "\n",
    "    def compute_mean(self, X, points):\n",
    "        \"\"\"\n",
    "        Compute the mean of all the samples belonging to a particular centroid.\n",
    "\n",
    "        Parameters:\n",
    "        X (np.ndarray) : Samples\n",
    "        points (np.ndarray) : Array consisting of indexes of the closest centroid to each sample in the dataset\n",
    "\n",
    "        Returns:\n",
    "        Centroids (np.ndarray) : Array consisting of the newly calculated centroids.\n",
    "        \"\"\"\n",
    "\n",
    "        centroids = np.zeros([self.K, X.shape[1]])\n",
    "        for i in range(self.K):\n",
    "            centroids_mean = X[i==points].mean(axis=0)\n",
    "            centroids[i] = centroids_mean\n",
    "\n",
    "        return centroids\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Cluster the dataset using the K-Means algorithm.\n",
    "        \n",
    "        Parameters:\n",
    "        X (numpy.ndarray): dataset to cluster\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray: array containing the final centroids for each cluster\n",
    "        numpy.ndarray: array containing the index of the centroid for each point\n",
    "        \"\"\"\n",
    "\n",
    "        self.initialize_centroids(X) # initialize the centroids\n",
    "        for i in range(self.max_iters):\n",
    "            points = self.assign_centroids(X) # assign each sample to the closest centroid\n",
    "            self.centroids = self.compute_mean(X, points) # update the centroids based on the mean of the current points in the cluster\n",
    "\n",
    "            assert len(self.centroids) == self.K, \"Number of centroids should equal K.\"\n",
    "            assert X.shape[1] == self.centroids.shape[1], \"Dimensionality of centroids should match input data.\"\n",
    "            assert max(points) < self.K, \"Cluster index should be less than K.\"\n",
    "            assert min(points) >= 0, \"Cluster index should be non-negative.\"\n",
    "            \n",
    "        return self.centroids, points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4ae73-eb8c-4e05-9af2-12ed6e2d117f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79336acd-b0f6-4a72-9a83-c6a17030f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de4bb1c9-2d65-4cfb-9118-427aab2557a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = Kmeans(3, 1000)\n",
    "centroids, points = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63c4a22c-a3c2-453f-809f-f5b883f957e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_43.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Cluster 1\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X[points==0, 0], y=X[points==0, 1],\n",
    "    mode='markers',marker_color='#491D8B',name='Iris-setosa'\n",
    "    ))\n",
    "\n",
    "# Cluster 2\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X[points==1, 0], y=X[points==1, 1],\n",
    "    mode='markers', marker_color='#7D3AC1',name='Iris-versicolor'\n",
    "    ))\n",
    "\n",
    "# Cluster 3\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X[points==2, 0], y=X[points==2, 1],\n",
    "    mode='markers', marker_color='#EB548C',name='Iris-virginica'\n",
    "    ))\n",
    "\n",
    "# Centroids\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=centroids[:, 0], y=centroids[:,1],\n",
    "    mode='markers',marker_color='white',marker_symbol=4,marker_size=13,name='Centroids'\n",
    "))\n",
    "fig.update_layout(template='plotly_dark', height=500, width=1000)\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37064d82-1169-4557-976c-bbb395a8d6f6",
   "metadata": {},
   "source": [
    "# Thank You\n",
    "If anyone has any suggestion, please do let me know."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
